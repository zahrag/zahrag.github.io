<!DOCTYPE html>
<html lang="en">
<head>
<!-- Polyfill for broader browser compatibility -->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

<!-- Load MathJax to display LaTeX equations -->
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIOSCAN-5M Portfolio</title>
<style>

body {
    font-family: Arial, sans-serif;
    margin: 0;
    padding: 0;
    display: flex;
    flex-direction: column;
    min-height: 100vh; /* Ensure the body takes full height */
    line-height: 1.6;
}

header {
    background-color: #282c34;
    color: #ffffff;
    padding: 10px;
    width: 100%;
    display: flex;
    justify-content: center;
    align-items: center;
    box-shadow: 0 4px 2px -2px gray;
    position: relative;
    z-index: 2; /* Ensure header is above other elements */
}

.header-container {
    text-align: center;
}

.header-title {
    font-size: 24px;
    font-weight: bold;
    margin: 0;
}

.sidebar {
    background-color: #f5f5f5;
    padding: 15px;
    padding-top: 150px; /* Add space at the top */
    width: 250px;
    height: 100vh;
    position: fixed;
    top: 0;
    left: 0;
}

.sidebar nav a {
    display: block;
    padding: 10px;
    text-decoration: none;
    color: #333;
    border-left: 3px solid transparent;
    /*margin-bottom: 5px;
    /*margin-top: 10px;  /*Add space above each link */
}

.sidebar nav a:first-child {
    margin-top: 0; /* Remove margin from the first link, if needed */
}


.content {
    margin-left: 270px; /* Space for the sidebar */
    padding: 20px;
    width: calc(100% - 350px); /* Adjust width to account for the sidebar */
    flex-grow: 1;
    overflow: auto; /* Ensure content scrolls if necessary */
}


footer {
      text-align: center;
      padding: 20px;
      margin-top: 40px;
      color: #aaa;
    }

img {
    height: auto;
    display: block;
    margin-left: auto;
    margin-right: auto;
}

/* Container for centering the figure */
.figure-container {
    text-align: center;
    margin: 0 auto;
    justify-content: flex-end; /* Align caption to the bottom */
    display: flex;
    flex-direction: column;
}


/* Styling for centered images */
.centered-image {
    display: block;
    margin: 0 auto;
    object-fit: cover;
}

/* Styling for captions */
.caption {
    /*font-style: italic;*/
    color: #555;
    margin-top: 8px;
}
.image-row {
    display: flex; /* Display images in a row */
    justify-content: center; /* Center the images horizontally */
    gap: 20px; /* Space between images */
}

h2 {
    border-bottom: 2px solid #d3d3d3; /* Changed from blue to top bar color */
    padding-bottom: 10px;
    margin-bottom: 20px;
}


h4 {
    border-bottom: 2px solid #d3d3d3; /* Changed from blue to top bar color */
    padding-bottom: 5px;
    margin-bottom: 20px;
}

li {
    margin-bottom: 3px; /* Adjust this value to control the vertical space */
}
@media (max-width: 768px) {
      .sidebar { display: none; }
      .content { margin-left: 0; padding: 100px 20px 20px; }
    }
</style>
</head>

<body>
  <header>
    <h1>Data Science Project: BIOSCAN-5M</h1>
  </header>

  <aside class="sidebar">
    <nav>
      <a href="index.html" style="margin-right: 20px;">Home</a>
      <a href="#description">Project Description</a>
      <a href="#contributions">Key Contributions</a>
      <a href="#tools">Tools & Technologies</a>
      <a href="#code">Code / Git</a>
      <a href="#research">Research / Paper</a>
      <a href="#presentation">Presentations</a>
      <a href="#links">Links & Resources</a>
      <a href="#additional-context"> Additional Context</a>
      <ul>
        <li><a href="#multiple-modalities"> Multiple Data Modalities</a></li>
        <li><a href="#stats"> Statistical Analysis</a></li>
        <li><a href="#ML-Benchmarks"> ML Benchmarks</a></li>

      </ul>
    </nav>
  </aside>

  <main class="content">
    <section id="description">
              <h2>Project Description</h2>
    <figure class="figure-container">
                <img src="images/BIOSCAN_5M.png" alt="BIOSCAN-5M"  width="1500" height="800">
                <figcaption class="caption">Sample image from BIOSCAN-1M Dataset</figcaption>
            </figure>
        <p>
         This project introduced a large-scale dataset of over five million samples, each consisting of
            a high-quality microscopic RGB image, a DNA barcode sequence, and a Barcode Index Number.
            The dataset comprises both structured and unstructured data formats.
            Structured data, provided in CSV and JSON-LD formats, includes taxonomy labels,
            DNA sequences, Barcode Index Numbers, geographic metadata, and specimen size information.
            Unstructured data consists primarily of images.
        </p>



    </section>

    <section id="contributions">
     <h2>Key Contributions</h2>
        <ul>
          <li>Led the design and coordination of a 5M-image multimodal dataset, guiding multi-partner teams through data curation, preprocessing, and machine learning experimentation.</li>
          <li>Developed preprocessing pipelines for image cropping, resizing, and bounding box extraction to support scalable training workflows.</li>
          <li>Structured image data and metadata for ML readiness, including split-aware subdirectories (pretrain, train, validation, test, val_unseen, test_unseen, etc.) and metadata in CSV and JSON-LD formats to ensure consistency across training and evaluation pipelines.</li>
          <li>Created a Hugging Face-compatible loader supporting resolution variants and
              standard ML splits (<a href="https://huggingface.co/datasets/bioscan-ml/BIOSCAN-5M" target="_blank">HuggingFace-Dataset</a>).</li>
            <li>Uploaded and organized datasets on cloud and open-access platforms to ensure accessibility and reproducibility (<a href="#links">Links & Resources</a>).</li>
            <li>Led benchmarking of multimodal classification and clustering models, providing baseline evaluations and performance tracking.</li>
            <li>Computed image-level statistics including bounding box-derived size features (area fraction, scale factor) to support downstream analyses.</li>
            <li>Provided Assistance in cleaning and standardized biological taxonomic labels to resolve annotation inconsistencies at scale..</li>
          <li>Curated and visualized biological, geographical, and genetic statistics across millions of records using dynamic tables and distribution plots.</li>
          <li>Analyzed taxonomic-level variation using pairwise genetic distance distributions
                and Shannon diversity index to support downstream ML task findings (<a href="https://github.com/zahrag/barcodemetrics" target="_blank">Barcode-Metrics</a>).</li>
        </ul>

    </section>

    <section id="tools">
      <h2>Tools & Technologies</h2>
    <ul>
      <li>Python, PyTorch, TensorFlow, Pandas, NumPy, PySpark (pyspark.sql) </li>
      <li>h5py, CSV, JSON, Pickle, Hugging Face Datasets</li>
      <li>Google API Client, PyDrive, Requests, google-auth</li>
      <li>Transformers (e.g., ViT, DetrFeatureExtractor), timm</li>
      <li>OpenCV, scikit-learn, PIL (Pillow)</li>
      <li>Matplotlib (mpl_toolkits), Seaborn, Plotly</li>
      <li>Cluster Computing, Parallel Computation</li>
      <li>Virtual Environment, Bash Environment</li>
      <li>Digital Research Alliance of Canada</li>
    </ul>
    </section>

    <section id="code">
      <h2>Code / Git</h2>
        <ul>
        <li><a href="https://github.com/bioscan-ml/BIOSCAN-5M" target="_blank">GitHub Page</a></li>
        </ul>
    </section>

    <section id="research">
      <h2>Research / Paper</h2>
        <ul>
        <li><a href="https://arxiv.org/abs/2406.12723" target="_blank">Paper</a></li>
        </ul>
    </section>

    <section id="presentation">
      <h2>Presentations</h2>
        <ul>
        <li><a href="https://arxiv.org/abs/2406.12723" target="_blank">Proceedings of NeurIPS 2024</a></li>
        </ul>
    </section>

      <section id="links">
          <h2>Links & Resources</h2>
                 <ul>
                    <li><a href="https://drive.google.com/drive/u/1/folders/1Jc57eKkeiYrnUBc9WlIp-ZS_L1bVlT-0" target="_blank">Google Drive</a></li>
                    <li><a href="https://huggingface.co/datasets/Gharaee/BIOSCAN-5M" target="_blank">Hugging Face</a></li>
                    <li><a href="https://zenodo.org/records/11973457" target="_blank">Zenodo</a></li>
                    <li><a href="https://www.kaggle.com/datasets/zahragharaee/bioscan-5m" target="_blank">Kaggle</a></li>
                </ul>
      </section>

   <section id="additional-context">
  <h2>Additional Context</h2>

  <section id="multiple-modalities">
    <h3>Multiple Data Modalities</h3>

    <article id="images">
      <h4>Images</h4>
      <p>The BIOSCAN-5M dataset contains 5,150,808 high-quality images of living organisms.</p>
      <figure class="figure-container">
        <img src="images/BS_5M_images.png" alt="BIOSCAN-5M Insect Project" class="centered-image" width="1300" height="1046">
        <figcaption class="caption">BIOSCAN-5M high-quality microscopic RGB images.</figcaption>
      </figure>
    </article>

    <article id="dna">
      <h4>DNA Nucleotide Barcode Sequences</h4>
      <p>The presented DNA barcode sequence illustrates the nucleotide arrangement—Adenine (A), Thymine (T), Cytosine (C), and Guanine (G)—within a designated gene region, such as the mitochondrial cytochrome c oxidase subunit I (COI) gene.</p>
      <pre style="background-color:#f4f4f4; padding:10px; border-radius:5px; overflow:auto;">
TTTATATTTTATTTTTGGAGCATGATCAGGAATAGTTGGAACTTCAATAAGTTTATTAATTCGAACAGAATTAAG...
      </pre>
      <figure>
        <img src="images/DNA_sequence.png" alt="Visual representation of DNA sequence" style="max-width:100%; height:auto;">
        <figcaption>This visual representation offers a glimpse into the intricate structure of DNA.</figcaption>
      </figure>

      <h5>Color Scheme</h5>
      <ul>
        <li><span style="color:red;">Adenine (A): Red</span></li>
        <li><span style="color:blue;">Thymine (T): Blue</span></li>
        <li><span style="color:green;">Cytosine (C): Green</span></li>
        <li><span style="color:#B8860B;">Guanine (G): Yellow</span></li>
      </ul>
    </article>

    <article id="taxonomy">
      <h4>Textual Taxonomy Labels</h4>
      <p>Taxonomic group ranking annotations categorize organisms hierarchically based on evolutionary relationships.</p>
      <figure class="figure-container">
        <img src="images/taxonomy.jpg" alt="Taxonomy" class="centered-image" width="900" height="900">
        <figcaption class="caption">Taxonomic Classification Tree.</figcaption>
      </figure>
    </article>

    <article id="geo">
      <h4>Geographic Information</h4>
      <p>Each dataset sample includes geographic information about the collection sites, captured through four key data attributes:</p>
      <h5>1- Latitude and 2- Longitude</h5>
      <figure class="figure-container">
        <img src="images/BS_5M_loc.png" alt="BIOSCAN-5M-lat-lon" class="centered-image" width="1000" height="5121">
        <figcaption class="caption">Locations associated with the sites of specimens collection.</figcaption>
      </figure>
      <h5>3- Country and 4- Province/State</h5>
      <figure class="figure-container">
        <img src="images/BS_5M_country.png" alt="BS-5M-country" class="centered-image" width="1000" height="1000">
        <figcaption class="caption">Countries associated with the sites of collection.</figcaption>
      </figure>
    </article>

    <article id="size">
      <h4>Size Information</h4>
      <p>Each dataset sample includes size information about each specimen, captured through three key data attributes:</p>

      <h5>1- Image Measurement Value</h5>
      <p>Count of pixels occupied by the organism in its image.</p>
      <figure class="figure-container">
        <img src="images/images_masks.png" alt="BS-5M-measu" class="centered-image" width="900" height="5121">
        <figcaption class="caption">Pixel count.</figcaption>
      </figure>

      <h5>2- Area Fraction</h5>
      <p>The fraction of the original image that the cropped image comprises based on bounding box information.</p>

      <h5>3- Scale Factor</h5>
      <p>The ratio of the cropped image to the cropped and resized image based on bounding box information.</p>

      <figure class="figure-container">
        <img src="images/area_frac.png" alt="BS-5M-bbx" class="centered-image" width="900" height="730">
        <figcaption class="caption">Bounding Box detected by our cropping tool.</figcaption>
      </figure>
    </article>
  </section>
    <section id="stats">
        <h3>Statistical Analytics</h3>
        <h4 id="bio_stat">Biological Statistics</h4>
        <iframe src="tables/table_BIOSCAN5M_bio.html" style="width: 100%; height: 500px; border: none;"></iframe>

        <h4 id="geo_stat">Geographical Statistics</h4>
        <iframe src="tables/table_BIOSCAN5M_geo.html" style="width: 100%; height: 300px; border: none;"></iframe>

        <h4 id="dna_stat">Genetic Statistics</h4>
        <iframe src="tables/table_BIOSCAN5M_dna.html" style="width: 100%; height: 500px; border: none;"></iframe>

        <figure class="figure-container">
            <img src="images/class_distance_distribution.png" alt="BS-5M-bbx" class="centered-image" width="900" height="730">
            <figcaption class="caption">Distribution of pairwise distances of subgroups of class...</figcaption>
        </figure>
        <figure class="figure-container">
            <img src="images/order_distance_distributions.png" alt="BS-5M-bbx" class="centered-image" width="900" height="730">
            <figcaption class="caption">Distribution of pairwise distances of subgroups of order...</figcaption>
        </figure>
        <figure class="figure-container">
            <img src="images/species_distance_distribution.png" alt="BS-5M-bbx" class="centered-image" width="900" height="730">
            <figcaption class="caption">Distribution of pairwise distances of subgroups of species...</figcaption>
        </figure>

        <h4 id="dists">Data Distributions</h4>
        <iframe src="tables/table_BIOSCAN5M_dists.html" style="width: 100%; height: 500px; border: none;"></iframe>
    </section>

    <section id="ML-Benchmarks">
        <h3>ML Benchmarks</h3>

        <h4>Data Partition</h4>
            <ul>
                <li><b>Seen:</b> Samples whose species label is an established scientific name of a species. Used in
                closed world settings.</li>
                <ul>
                    <li>train</li>
                    <li>val</li>
                    <li>test</li>
                </ul>
                <li><b>Unseen:</b> labelled with an established scientific name for the genus, and a uniquely identifying placeholder name for the species.
                Used in open world settings.</li>
                 <ul>
                    <li>key_unseen</li>
                    <li>val_unseen</li>
                    <li>test_unseen</li>
                </ul>
                <li><b>Heldout:</b> labelled with a placeholder genus and species name. Used in novelty detection.</li>
                 <ul>
                    <li>other_heldout</li>
                </ul>
                <li><b>Unknown:</b> samples without a species label.
                Used in self- and semi-supervised learning.</li>
                 <ul>
                    <li>pretrain</li>
                </ul>
            </ul>
            <figure class="figure-container">
                    <img src="images/split_plot.png" alt="split" class="centered-image" width="500" height="500">
                    <figcaption class="caption">Data split distribution to facilitate closed world and open world settings. </figcaption>
            </figure>


        <h4>Barcode-BERT: DNA Sequence Classification</h4>
        <p>Two stages of the proposed semi-supervised learning set-up based on BarcodeBERT <a href="https://arxiv.org/abs/2311.02401" target="_blank">Arias et al. (2023)</a>.
            (1) Pretraining: DNA sequences are tokenized using non-overlapping k-mers and 50% of the tokens
            are masked for the MLM task. Tokens are encoded and fed into a transformer model. The output
            embeddings are used for token-level classification. (2) Fine-tuning: All DNA sequences in a
            dataset are tokenized using non-overlapping k-mer tokenization and all tokenized sequences, without
            masking, are passed through the pretrained transformer model. Global mean-pooling is applied over
                the token-level embeddings and the output is used for taxonomic classification. </p>

            <p>The results are presented in <a href="https://arxiv.org/abs/2406.12723" target="_blank">Gharaee et al. (2024)</a></p>
            <figure class="figure-container">
                    <img src="images/barcode_bert_n2.png" alt="BS-5M-bert" class="centered-image" width="730" height="730">
                    <figcaption class="caption">Barcode Bert model. </figcaption>
                </figure>

        <h4>Zero-shot Clustering</h4>
        <p>Images and DNA are each passed through one of several pretrained encoders.
                These representations are clustered with Agglomerative Clustering.</p>

            <p>The results are presented in <a href="https://arxiv.org/abs/2406.12723" target="_blank">Gharaee et al. (2024)</a></p>
            <figure class="figure-container">
                    <img src="images/bioscan_zsc_n1.png" alt="BS-5M-bert" class="centered-image" width="730" height="730">
                    <figcaption class="caption">Zero-shot clustering. </figcaption>
                </figure>

        <h4>BIOSCAN-CLIBD: Multi-modal Contrastive Learning</h4>
      <p>Our experiments using the BIOSCAN-CLIBD <a href="https://arxiv.org/abs/2405.17537" target="_blank">Gong et al. (2024)</a> are conducted in two steps. (1) Training:
            Multiple modalities, including RGB images, textual taxonomy, and DNA sequences, are encoded
            separately, and trained using a contrastive loss function. (2) Inference: Image vs DNA embedding
            is used as a query, and compared to the embeddings obtained from a database of image, DNA and
            text (keys). The cosine similarity is used to find the closest key embedding, and the corresponding
                taxonomic label is used to classify the query.</p>

            <figure class="figure-container">
                    <img src="images/bioscan_clip.png" alt="BS-5M-bert" class="centered-image" width="730" height="730">
                    <figcaption class="caption">BIOSCAN-CLIBD model. </figcaption>
            </figure>

              <p> We report top-1 macro accuracy (%) on the test set using different amounts of pre-training data
                (1 million vs. 5 million records from BIOSCAN-5M) and various combinations of aligned embeddings (image, DNA, and text)
                during contrastive training. Our results include accuracy for image-to-image, DNA-to-DNA, and image-to-DNA query-key combinations.
                As a baseline, we provide the results without contrastive learning (no alignment).
                We report accuracy separately for seen and unseen species, along with the harmonic mean (H.M.) between these values.</p>

            <h4>BIOSCAN-CLIBD predicting <b>orders</b></h4>
            <figure class="figure-container">
                    <img src="images/bar_Order.png" alt="split" class="centered-image" width="1000" height="1000">
            </figure>
            <h4>BIOSCAN-CLIBD predicting <b>families</b></h4>
             <figure class="figure-container">
                    <img src="images/bar_Family.png" alt="BS-5M-bert" class="centered-image" width="1000" height="1000">
            </figure>
            <h4>BIOSCAN-CLIBD predicting <b>genus</b></h4>
             <figure class="figure-container">
                    <img src="images/bar_Genus.png" alt="BS-5M-bert" class="centered-image" width="1000" height="1000">
            </figure>
            <p></p>
            <h4>BIOSCAN-CLIBD predicting <b>species</b></h4>
             <figure class="figure-container">
                    <img src="images/bar_Species.png" alt="BS-5M-bert" class="centered-image" width="1000" height="1000">
            </figure>
            <p>The results details are presented in <a href="https://arxiv.org/abs/2406.12723" target="_blank">Gharaee et al. (2024)</a></p>

    </section>
</section>




    <footer>
      &copy; 2025 Zahra Gharaee. All rights reserved.
    </footer>
  </main>
</body>
</html>
