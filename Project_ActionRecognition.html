<!DOCTYPE html>
<html lang="en">
<head>
<!-- Polyfill for broader browser compatibility -->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

<!-- Load MathJax to display LaTeX equations -->
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SuperFormer Portfolio</title>
<style>

body {
    font-family: Arial, sans-serif;
    margin: 0;
    padding: 0;
    display: flex;
    flex-direction: column;
    min-height: 100vh; /* Ensure the body takes full height */
    line-height: 1.6;
}

header {
    background-color: #282c34;
    color: #ffffff;
    padding: 10px;
    width: 100%;
    display: flex;
    justify-content: center;
    align-items: center;
    box-shadow: 0 4px 2px -2px gray;
    position: relative;
    z-index: 2; /* Ensure header is above other elements */
}

.header-container {
    text-align: center;
}

.header-title {
    font-size: 24px;
    font-weight: bold;
    margin: 0;
}

.sidebar {
    background-color: #f5f5f5;
    padding: 15px;
    padding-top: 150px; /* Add space at the top */
    width: 250px;
    height: 100vh;
    position: fixed;
    top: 0;
    left: 0;
}

.sidebar nav a {
    display: block;
    padding: 10px;
    text-decoration: none;
    color: #333;
    border-left: 3px solid transparent;
    /*margin-bottom: 5px;
    /*margin-top: 10px;  /*Add space above each link */
}

.sidebar nav a:first-child {
    margin-top: 0; /* Remove margin from the first link, if needed */
}


.content {
    margin-left: 270px; /* Space for the sidebar */
    padding: 20px;
    width: calc(100% - 350px); /* Adjust width to account for the sidebar */
    flex-grow: 1;
    overflow: auto; /* Ensure content scrolls if necessary */
}


footer {
      text-align: center;
      padding: 20px;
      margin-top: 40px;
      color: #aaa;
    }

img {
    height: auto;
    display: block;
    margin-left: auto;
    margin-right: auto;
}

/* Container for centering the figure */
.figure-container {
    text-align: center;
    margin: 0 auto;
    justify-content: flex-end; /* Align caption to the bottom */
    display: flex;
    flex-direction: column;
}


/* Styling for centered images */
.centered-image {
    display: block;
    margin: 0 auto;
    object-fit: cover;
}

/* Styling for captions */
.caption {
    /*font-style: italic;*/
    color: #555;
    margin-top: 8px;
}
.image-row {
    display: flex; /* Display images in a row */
    justify-content: center; /* Center the images horizontally */
    gap: 20px; /* Space between images */
}

h2 {
    border-bottom: 2px solid #282c34; /* Changed from blue to top bar color */
    padding-bottom: 10px;
    margin-bottom: 20px;
}

h3 {
    border-bottom: 2px solid #d3d3d3; /* Changed from blue to top bar color */
    padding-bottom: 5px;
    margin-bottom: 20px;
}

li {
    margin-bottom: 3px; /* Adjust this value to control the vertical space */
}
</style>

</head>
<body>
    <header>
        <div class="header-container">
            <h1>Computer Vision Project: SuperFormer</h1>
        </div>
    </header>

    <aside class="sidebar">
    <nav>
      <a href="index.html" style="margin-right: 20px;">Home</a>
      <a href="#description">Project Description</a>
      <a href="#contributions">Key Contributions</a>
      <a href="#tools">Tools & Technologies</a>
      <a href="#code">Code / Git</a>
      <a href="#research">Research / Paper</a>
    </nav>
  </aside>

    <main class="content">
        <section id="description">
            <h2>Project Description</h2>
            <figure class="figure-container">
                <img src="images/hr.png" alt="HUman Action Recognition" class="centered-image" width="1200" height="500">
                <figcaption class="caption">Self-supervised Learning of 3D Skeleton Based Human Action Recognition</figcaption>
            </figure>
            <p><b>3D-Skeleton Human Action Recognition:</b> This project proposed an unsupervised approach for human action recognition, conducted in multiple phases:</p>
           <ul>
            <li>Applied first- and second-order dynamics for 3D skeleton-based human action recognition using self-organizing neural networks.</li>
            <li>Designed and implemented an online action recognition system.</li>
            <li>Developed a self-organizing architecture with a growing grid network to enhance recognition performance.</li>
            <li>Built an online action recognition framework capable of handling unsegmented streams of action frames.</li>
        </ul>
        </section>

  <section id="contributions">
  <h2>Key Contributions</h2>
  <ul>
      <li>Designed and implemented a human action recognition system that, when paired with a Kinect sensor, receives and preprocesses action data, extracts 3D joint information, and recognizes performed actions.</li>
      <li>Validated the proposed pipeline on multiple publicly available datasets, including MSRAction3D, UTKinect, and Florence3DActions.</li>
      <li>Collaborated as a researcher on the <a href="https://cordis.europa.eu/project/id/612139" target="_blank">What You Say Is What You Did (EU FET WYSIWYD)</a>, a multiple partner project.</li>
      <li>Contributing to the <a href="https://www.ikaros-project.org/" target="_blank"> Ikaros: An infrastructure for system level modelling of the brain</a>, a multiple partner project.</li>
      <li>Participating in the <a href="https://portal.research.lu.se/en/projects/thinking-in-time-cognition-communication-and-learning/" target="_blank">
Thinking in Time: Cognition, Communication and Learning</a>, a multiple partner project.</li>

  </ul>
</section>

  <section id="tools">
      <h2>Tools & Technologies</h2>
    <ul>
      <li>C++, Python </li>
      <li>Matplotlib (mpl_toolkits), Seaborn, Plotly, Visdom</li>
      <li>Container (Singularity, Docker)</li>
      <li>Cluster Computing, Parallel Computation</li>
      <li>Virtual Environment, Bash Environment</li>
    </ul>
    </section>

    <section id="code">
      <h2>Code / Git</h2>
        <ul>
        <li><a href="https://github.com/zahrag/3DHARSOM" target="_blank">3DHARSOM GitHub Page</a></li>
        <li><a href="https://github.com/zahrag/gg3dhar" target="_blank">gg3dhar GitHub Page</a></li>

        </ul>
    </section>

    <section id="research">
      <h2>Research / Paper</h2>
        <ul>
        <li><a href="https://arxiv.org/abs/2104.06059" target="_blank">Dynamic</a></li>
        <li><a href="https://arxiv.org/abs/2104.06070" target="_blank">Online</a></li>
        <li><a href="https://arxiv.org/abs/2104.11165" target="_blank">GG-Network</a></li>
        <li><a href="https://arxiv.org/abs/2104.11637" target="_blank">Unsegmented</a></li>

        </ul>
    </section>

    <section id="presentation">
      <h2>Presentations</h2>
        <ul>
        <li><a href="https://ieeexplore.ieee.org/xpl/conhome/7906442/proceeding" target="_blank">12th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS 2016)</a></li>
        <li><a href="https://icaart.scitevents.org/?y=2017" target="_blank">9th International Conference on Agents and Artificial Intelligence (ICAART 2017)</a></li>
        <li><a href="https://www.proceedings.com/38445.html" target="_blank">8th Annual International Conference on Biologically Inspired Cognitive Architectures (BICA 2017)</a></li>
        <li>International Conference on Neural Networks (ICNN 2018)</li>
        </ul>
    </section>



    </main>

    <footer>
        <p>&copy; 2024 Zahra Gharaee. All rights reserved.</p>
    </footer>
</body>
</html>
