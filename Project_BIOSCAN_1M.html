<!DOCTYPE html>
<html lang="en">
<head>
<!-- Polyfill for broader browser compatibility -->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

<!-- Load MathJax to display LaTeX equations -->
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIOSCAN-1M Portfolio</title>
<style>

body {
    font-family: Arial, sans-serif;
    margin: 0;
    padding: 0;
    display: flex;
    flex-direction: column;
    min-height: 100vh; /* Ensure the body takes full height */
    line-height: 1.6;
}

header {
    background-color: #282c34;
    color: #ffffff;
    padding: 10px;
    width: 100%;
    display: flex;
    justify-content: center;
    align-items: center;
    box-shadow: 0 4px 2px -2px gray;
    position: relative;
    z-index: 2; /* Ensure header is above other elements */
}

.header-container {
    text-align: center;
}

.header-title {
    font-size: 24px;
    font-weight: bold;
    margin: 0;
}

.sidebar {
    background-color: #f5f5f5;
    padding: 15px;
    padding-top: 150px; /* Add space at the top */
    width: 250px;
    height: 100vh;
    position: fixed;
    top: 0;
    left: 0;
}

.sidebar nav a {
    display: block;
    padding: 10px;
    text-decoration: none;
    color: #333;
    border-left: 3px solid transparent;
    /*margin-bottom: 5px;
    /*margin-top: 10px;  /*Add space above each link */
}

.sidebar nav a:first-child {
    margin-top: 0; /* Remove margin from the first link, if needed */
}


.content {
    margin-left: 270px; /* Space for the sidebar */
    padding: 20px;
    width: calc(100% - 350px); /* Adjust width to account for the sidebar */
    flex-grow: 1;
    overflow: auto; /* Ensure content scrolls if necessary */
}


footer {
      text-align: center;
      padding: 20px;
      margin-top: 40px;
      color: #aaa;
    }

img {
    height: auto;
    display: block;
    margin-left: auto;
    margin-right: auto;
}

/* Container for centering the figure */
.figure-container {
    text-align: center;
    margin: 0 auto;
    justify-content: flex-end; /* Align caption to the bottom */
    display: flex;
    flex-direction: column;
}


/* Styling for centered images */
.centered-image {
    display: block;
    margin: 0 auto;
    object-fit: cover;
}

/* Styling for captions */
.caption {
    /*font-style: italic;*/
    color: #555;
    margin-top: 8px;
}
.image-row {
    display: flex; /* Display images in a row */
    justify-content: center; /* Center the images horizontally */
    gap: 20px; /* Space between images */
}

h2 {
    border-bottom: 2px solid #d3d3d3; /* Changed from blue to top bar color */
    padding-bottom: 10px;
    margin-bottom: 20px;
}


h4 {
    border-bottom: 2px solid #d3d3d3; /* Changed from blue to top bar color */
    padding-bottom: 5px;
    margin-bottom: 20px;
}

li {
    margin-bottom: 3px; /* Adjust this value to control the vertical space */
}
@media (max-width: 768px) {
      .sidebar { display: none; }
      .content { margin-left: 0; padding: 100px 20px 20px; }
    }
</style>
</head>

<body>
  <header>
    <h1>Data Science Project: BIOSCAN-1M</h1>
  </header>

  <aside class="sidebar">
    <nav>
      <a href="index.html" style="margin-right: 20px;">Home</a>
      <a href="#description">Project Description</a>
      <a href="#contributions">key Contributions</a>
      <a href="#tools">Tools & Technologies</a>
      <a href="#code">Code / Git</a>
      <a href="#research">Research / Paper</a>
      <a href="#presentation">Presentations</a>
      <a href="#links">Links & Resources</a>
      <a href="#additional-context"> Additional Context</a>
      <ul>
        <li><a href="#stats"> Statistical Analysis</a></li>
        <li><a href="#ML-Benchmark"> ML Benchmarks</a></li>
        <li><a href="#Deployment"> Deployment</a></li>

      </ul>
    </nav>
  </aside>

  <main class="content">
       <section id="description">
             <h2>Project Description</h2>
             <figure class="figure-container">
                <img src="images/BIOSCAN_1M.png" alt="BIOSCAN-1M"  width="1500" height="800">
                <figcaption class="caption">Sample image from BIOSCAN-1M Dataset</figcaption>
            </figure>
        <p>BIOSCAN-1M is a large-scale dataset combining over 1 million RGB microscopic images with metadata such as DNA barcode sequences and taxonomy. It supports biodiversity and AI research through multimodal learning.</p>
    </section>

  <section id="contributions">
  <h2>Key Contributions</h2>
  <ul>
    <li>Led dataset design and governance, defining taxonomy-aware sampling strategies and class-balanced, stratified splits for small, medium, and large dataset variants.</li>
    <li>Developed robust ETL pipelines for large-scale image preprocessing (cropping, resizing, HDF5 conversion) and metadata structuring (CSV, JSON-LD) to support downstream ML tasks.</li>
    <li>Implemented and automated the full ML pipeline, from data preparation through model training and benchmarking, using cloud-hosted storage and reproducible configurations.</li>
    <li>Fine-tuned ResNet50 and Vision Transformer (ViT) backbones using transfer learning for multi-class classification, evaluating model performance across 72 controlled experiments.</li>
    <li>Benchmarked classification models with systematic variation of task type, architecture, loss function, and random seed to assess robustness and generalization.</li>
    <li>Ensured reproducibility and experimental rigor through repeated runs and standardized evaluation metrics, including accuracy, F1-score, confusion matrices, and tabular summaries.</li>
  </ul>
</section>


    <section id="tools">
      <h2>Tools & Technologies</h2>
    <ul>
      <li>Python, PyTorch, Pandas, NumPy</li>
      <li>h5py, CSV, JSON, Pickle, Hugging Face Datasets</li>
      <li>Google API Client, PyDrive, Requests, google-auth</li>
      <li>Transformers (e.g., ViT, DetrFeatureExtractor), timm</li>
      <li>OpenCV, scikit-learn, PIL (Pillow)</li>
      <li>Matplotlib, Seaborn, Plotly</li>
      <li>Cluster Computing, Parallel Computation</li>
      <li>Virtual Environment, Bash Environment</li>
      <li>Digital Research Alliance of Canada</li>
    </ul>
    </section>

    <section id="code">
      <h2>Code / Git</h2>
        <ul>
      <li><a href="https://github.com/bioscan-ml/BIOSCAN-1M" target="_blank">GitHub Repository</a></li>
        </ul>
    </section>

    <section id="research">
      <h2>Research / Paper</h2>
        <ul>
      <li><a href="https://arxiv.org/abs/2307.10455" target="_blank">Paper</a></li>
        </ul>
    </section>

    <section id="presentation">
      <h2>Presentations</h2>
        <ul>
        <li><a href="https://neurips.cc/virtual/2023/poster/73549" target="_blank">Proceedings of NeurIPS 2023</a></li>
        </ul>
    </section>

      <section id="links">
          <h2>Links & Resources</h2>
                <ul>
                    <li><a href="https://drive.google.com/drive/u/1/folders/1kD9cXuQ1FdL30etp7sjy_Gs_NAAJ3EXI" target="_blank">Google Drive</a></li>
                    <li><a href="https://huggingface.co/datasets/Gharaee/BIOSCAN_1M_Insect_Dataset" target="_blank">Hugging Face</a></li>
                    <li><a href="https://zenodo.org/records/8030065" target="_blank">Zenodo</a></li>
                    <li><a href="https://www.kaggle.com/datasets/zahragharaee/bioscan-1m-insect-dataset" target="_blank">Kaggle</a></li>
                </ul>
      </section>


     <section id="additional-context">
      <h2>Additional Context</h2>

      <section id="stats">
         <h3>Statistical Analysis</h3>
         <p><strong>Fine-Grained Classification</strong></p>
         <p>Fine-grained classification involves distinguishing between classes that are very similar to each other,
            often requiring detailed and nuanced feature analysis. In taxonomic classification, this concept
            is illustrated as we move from broader, less specific levels (e.g., phylum, class) to
            more specific levels (e.g., genus, species) within the taxonomic tree.
             This necessitates a classification model that can accurately differentiate between these closely related classes.</p>

         <figure class="figure-container">
                <img src="images/Taxonomy_horiz_upd1.png" alt="Taxonomy Classification" class="centered-image" width="1000" height="1000">
                <figcaption class="caption">Taxonomy Classification.</figcaption>
            </figure>

         <p><strong>Long-Tailed Distribution</strong></p>
            <p>The BIOSCAN-1M dataset exhibits a long-tailed distribution,
                where a small number of classes have a large number of samples, while most classes have very few samples.
                This distribution can result in models that perform well on the frequently occurring classes but
                struggle with the underrepresented classes due to insufficient training data.
                For instance, in the BIOSCAN-1M dataset, the order Diptera contains 896,324 samples out of
                a total of 1,128,313, which represents approximately 80% of all samples. This illustrates how a few classes dominate the dataset,
                    highlighting the long-tailed nature of the distribution.</p>

            <figure class="figure-container">
                <img src="images/BS_1M_Order.png" alt="Class distribution of taxonomy group order" class="centered-image" width="700" height="700">
                <figcaption class="caption">Class Distribution of taxonomy group order.</figcaption>
            </figure>

         <p><strong>High Class Imbalance Ratio</strong></p>
                <p>There is a significant class imbalance in the BIOSCAN-1M dataset, with some classes
                    being heavily underrepresented compared to others. This high class imbalance ratio can lead to
                    biases in model training, where the model becomes skewed towards the majority classes and
                    shows poor performance on the minority classes. Addressing this imbalance is crucial
                    for ensuring the model's effectiveness across all classes.</p>
            <iframe src="tables/table_BIOSCAN_1M_stats.html" style="width: 100%; height: 280px; border: none;"></iframe>
        </section>

        <section id="ML-Benchmark">
            <h3>ML Benchmarks</h3>
            <p>This section outlines the machine learning benchmark tasks and results for the BIOSCAN-1M dataset. The benchmarks were designed to evaluate classification performance at different taxonomy levels and dataset sizes.</p>
            <h3>Data Sampling</h3>
            <p>The BIOSCAN-1M dataset was sampled in the following ways:</p>
            <ul>
                <p><strong>Taxonomy Levels:</strong> Two datasets were created:</p>
                <ul>
                    <li><strong>BIOSCAN-1M-Insect:</strong> Samples at the taxonomy order level.</li>
                    <li><strong>BIOSCAN-1M-Diptera:</strong> Samples at the taxonomy family (Diptera) level.</li>
                </ul>

                <p><strong>Dataset Sizes:</strong> Each dataset was further divided into three sizes to address usability and feasibility for end users in various domains:</p>
                <ul>
                    <li><strong>Small:</strong> 50,000 samples</li>
                    <li><strong>Medium:</strong> 200,000 samples</li>
                    <li><strong>Large:</strong>
                        <ul>
                            <li><strong>Order:</strong> 1,100,000 samples</li>
                            <li><strong>Diptera:</strong> 891,000 samples</li>
                        </ul>
                    </li>
                </ul>

            </ul>
            <h4>Stratified Class-Based Split</h4>
            <p>Data samples for each dataset size were split into train (70%), validation (10%), and test (20%) sets using a class-based mechanism to ensure consistent data distributions across all sets.</p>
            <h4>Multi-class Classification</h4>
            <p>Two image-based classification benchmark experiments were designed and conducted on all three sized datasets:</p>
            <ul>
                <li><strong>Insect-Order:</strong> 16 classes.</li>
                <li><strong>Family-Diptera:</strong> 40 classes.</li>
            </ul>
            <figure class="figure-container">
                <img src="images/BIOSCAN_Fig2_upd3.png" alt="Class distribution" class="centered-image" width="1000" height="1000">
                <figcaption class="caption">Class distribution of the two sampled datasets.</figcaption>
            </figure>
            <h4>Transfer Learning</h4>
            <p>Dataset was fine-tuned utilizing two pretrained backbone models to facilitate transfer learning:
                <ul>
                    <li><strong>ResNet50:</strong> A deep residual learning framework for image recognition. <a href="https://arxiv.org/abs/1512.03385" target="_blank">He et al. (2016)</a></li>
                    <li><strong>Vision Transformer (ViT-B/16-224):</strong> A transformer-based model for image classification. <a href="https://arxiv.org/abs/2010.11929" target="_blank">Dosovitskiy et al. (2020)</a></li>
                </ul>
            </p>
            <h4>Robustness and Generalizability</h4>
                <p>To ensure the robustness and generalizability of the models, each experiment was repeated
                    with 3 different random seeds. This approach allows us to account for the impact of randomness in our results.
                    The total number of experiments conducted is given by:
                </p>
                <p>3 (dataset sizes) × 2 (classification tasks) × 2 (backbone models) × 2 (loss functions) × 3 (seeds) = 72</p>
            <p>To see the results these experiments with mean and standard deviation please visit <b>Tables A3-A4</b> <a href="https://arxiv.org/abs/2307.10455" target="_blank">Gharaee et al. (2023)</a>.</p>


            <h4>Evaluation</h4>
             <p>The model with the best performance on the validation set is selected and used for test experiments.
                 The metrics used for the evaluation are as follows:
                </p>
            <ul>
                <li><strong>Top-1 Accuracy:</strong> The proportion of test samples where the top predicted class matches the true label.</li>
                <li><strong>Top-5 Accuracy:</strong> The proportion of test samples where the true label is among the top five predicted classes.</li>
                <li><strong>Macro-F1 Score:</strong> The macro-averaged F1 score, which computes the F1 score for each class and then averages these scores, giving equal weight to each class.</li>
                <li><strong>Loss:</strong> Monitored during training and evaluated post-training to measure the effectiveness of the model’s learning.</li>
            </ul>
            <h4>Findings and Results</h4>
            <p>The results indicate that:</p>
            <ul>
                <li><strong>Cross-Entropy:</strong> Generally performed better achieving higher accuracy.</li>
                <li><strong>Vision Transformer:</strong> Demonstrated competitive performance, especially on larger datasets, showing its robustness and capability in handling high-dimensional image data.</li>
            </ul>
            <figure class="figure-container">
                <img src="images/BIOSCAN_Fig5_upd3_.png" alt="results" class="centered-image", width="1000" height="1000">
                <figcaption class="caption">Per-class top-1 test accuracy of the Insect-Order and Diptera-Family classification
                    experiments of the Large dataset.</figcaption>
            </figure>
            <figure class="figure-container">
                <img src="images/confusion_insect.png" alt="results" class="centered-image", width="1000" height="1000">
                <figcaption class="caption">Confusion Matrix of insect-order experiments.</figcaption>
            </figure>
            <figure class="figure-container">
                <img src="images/confusion_diptera.png" alt="results" class="centered-image", width="1300" height="1000">
                <figcaption class="caption">Confusion Matrix of diptera-family experiments.</figcaption>
            </figure>
            <iframe src="tables/table_BIOSCAN_1M_results.html" style="width: 100%; height: 400px; border: none;"></iframe>
        </section>

        <section id="Deployment">
            <h3>Deployment</h3>
            <p>The model trained on BIOSCAN-1M datasets are stored in project's Google Drive folder.
               The pretrained models, and its AI-based tool are utilized by biologists at the
                Centre for Biodiversity Genomics (CBG) to streamline biological taxonomy classification.
                Traditionally performed by human experts, this process is costly, and time-consuming.
            </p>
        </section>
    </section>

    <footer>
      &copy; 2025 Zahra Gharaee. All rights reserved.
    </footer>
  </main>
</body>
</html>
